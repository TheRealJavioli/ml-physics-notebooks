{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is a simple notebook to build and visualize decision trees.\n",
    "\n",
    "It accompanies Chapter 2 of the book.\n",
    "\n",
    "Author: Viviana Acquaviva\n",
    "    \n",
    "Some visualization-inspiration credits:\n",
    "\n",
    "https://towardsdatascience.com/scikit-learn-decision-trees-explained-803f3812290d\n",
    "\n",
    "https://medium.com/@rnbrown/creating-and-visualizing-decision-trees-with-python-f8e8fa394176\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "import pandas as pd #new!\n",
    "\n",
    "from sklearn.model_selection import train_test_split #we don't use it here, but it's a useful function!\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier #how methods are imported \n",
    "\n",
    "from sklearn import metrics #this will give us access to evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'size'   : 20}\n",
    "matplotlib.rc('font', **font)\n",
    "matplotlib.rc('xtick', labelsize=20) \n",
    "matplotlib.rc('ytick', labelsize=20) \n",
    "matplotlib.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is a bunch of packages for visualization purposes only - this cell can be skipped if troublesome\n",
    "\n",
    "from io import StringIO\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz #you can just use this if the other lines give troubles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We use a selection of data from http://phl.upr.edu/projects/habitable-exoplanets-catalog/data/database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We begin by reading in the data set using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearningSet = pd.read_csv('HPLearningSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head 'HPLearningSet.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearningSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearningSet = LearningSet.drop(LearningSet.columns[0], axis=1) #We want to drop the first column of the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure we created is called a data frame.\n",
    "\n",
    "It's nice because we can refer to columns with their names as well as indices, and it looks neat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearningSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearningSet[['P_NAME','S_MASS']] #convenient way to access columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LearningSet.P_NAME #another one!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's pick the same train/test set we had in the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the use of \".iloc\" (integer location) to access indices in data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet =  LearningSet.iloc[:13,:]  #normally this would happen at random, using the function train_test_split\n",
    "\n",
    "TestSet = LearningSet.iloc[13:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We split the train and test sets in features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = TrainSet.drop(['P_NAME','P_HABITABLE'],axis=1) #features for the train set\n",
    "\n",
    "Xtest = TestSet.drop(['P_NAME','P_HABITABLE'],axis=1) #features for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = TrainSet.P_HABITABLE #target for the train set\n",
    "\n",
    "ytest = TestSet.P_HABITABLE  #target for the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And we are ready to fit the model with our decision tree!\n",
    "\n",
    "Note: The features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data, if the improvement of the criterion is identical for several splits enumerated during the search of the best split. \n",
    "\n",
    "To obtain a deterministic behaviour during fitting, random_state has to be fixed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(random_state = 3) #This is how we specify which method we'd like to use, and any parameters.\n",
    "\n",
    "model.fit(Xtrain, ytrain) #This tiny line is how we build models in sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, we can visualize the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(\n",
    "            model,\n",
    "            out_file =  dot_data,\n",
    "            feature_names = ['Stellar Mass (M*)', 'Orbital Period (d)', 'Distance (AU)'],\n",
    "            class_names = ['Not Habitable','Habitable'],\n",
    "            filled = True,\n",
    "            rounded = True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "nodes = graph.get_node_list()\n",
    "\n",
    "for node in nodes:\n",
    "    if node.get_label():\n",
    "        values = [int(ii) for ii in node.get_label().split('value = [')[1].split(']')[0].split(',')]\n",
    "        values = [255 * v / sum(values) for v in values]\n",
    "        \n",
    "        values = [int(255 * v / sum(values)) for v in values]\n",
    "            \n",
    "        if values[0] > values[1]:\n",
    "            alpha = int(values[0] - values[1])\n",
    "            alpha = '{:02x}'.format(alpha) #turn into hexadecimal\n",
    "            color = '#20 B2 AA'+str(alpha)\n",
    "        else:\n",
    "            alpha = int(values[1] - values[0])\n",
    "            alpha = '{:02x}'.format(alpha)\n",
    "            color = '#FF 00 FF'+str(alpha)\n",
    "        node.set_fillcolor(color)\n",
    "\n",
    "graph.set_dpi('300')\n",
    "\n",
    "Image(graph.create_png())\n",
    "\n",
    "#Image(graph.write_png('Graph.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is an alternative visualization, which only relies on the sklearn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(40,20))  # customize according to the size of your tree\n",
    "\n",
    "tree.plot_tree(model, feature_names = ['Stellar Mass (M*)', 'Orbital Period (d)', 'Distance (AU)'], class_names = ['Not Habitable','Habitable'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can visualize the splits as well and then answer some questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", ['#20B2AA','#FF00FF'])\n",
    "\n",
    "#Will now plot the train set and test set points\n",
    "\n",
    "plt.scatter(TrainSet['S_MASS'], TrainSet['P_PERIOD'], marker = '*',\\\n",
    "            c = TrainSet['P_HABITABLE'], s = 100, cmap=cmap, label = 'Train')\n",
    "\n",
    "plt.scatter(TestSet['S_MASS'], TestSet['P_PERIOD'], marker = 'o',\\\n",
    "            c = TestSet['P_HABITABLE'], s = 100, cmap=cmap, label = 'Test')\n",
    "\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.xlabel('Mass of Parent Star (Solar Mass Units)')\n",
    "\n",
    "plt.ylabel('Period of Orbit (days)');\n",
    "\n",
    "#I can add the splits to the plot\n",
    "\n",
    "plt.axvline(x=0.83, linewidth =1, ls = '-', label = '1st split', c='k')\n",
    "\n",
    "plt.axhline(y=4.891, xmin = 0, xmax = 0.655, linewidth =1, ls = '--', label = '2nd split',c='k')\n",
    "\n",
    "plt.text(0.845, 10**3, '1st split', fontsize=14)\n",
    "         \n",
    "plt.text(0.65, 6, '2nd split', fontsize=14)\n",
    "\n",
    "#Add legend, including unlabeled objects\n",
    "\n",
    "bluepatch = mpatches.Patch(color='#20B2AA', label='Not Habitable')\n",
    "\n",
    "magentapatch = mpatches.Patch(color='#FF00FF', label='Habitable')\n",
    "\n",
    "plt.legend();\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "predhab = mpatches.Rectangle((0,4.891),0.83,ax.get_ylim()[1], \n",
    "                        fill = True,\n",
    "                        color = '#FF00FF',\n",
    "                        alpha = 0.3)\n",
    "\n",
    "prednothab1 = mpatches.Rectangle((0.83,ax.get_ylim()[0]),ax.get_xlim()[1],ax.get_ylim()[1], \n",
    "                        fill = True,\n",
    "                        color = '#20B2AA',\n",
    "                        alpha = 0.3)\n",
    "\n",
    "prednothab2 = mpatches.Rectangle((0,ax.get_ylim()[0]),0.83,4.891-ax.get_ylim()[0], \n",
    "                        fill = True,\n",
    "                        color = '#20B2AA',\n",
    "                        alpha = 0.3)\n",
    "\n",
    "leg = ax.get_legend()\n",
    "leg.legendHandles[2].set_color('k')\n",
    "leg.legendHandles[3].set_color('k')\n",
    "\n",
    "plt.gca().add_patch(predhab)\n",
    "plt.gca().add_patch(prednothab1)\n",
    "plt.gca().add_patch(prednothab2)\n",
    "\n",
    "leg = ax.get_legend()\n",
    "leg.legendHandles[2].set_color('k')\n",
    "leg.legendHandles[3].set_color('k')\n",
    "\n",
    "\n",
    "plt.legend(handles=[leg.legendHandles[2],leg.legendHandles[3], magentapatch, bluepatch],\\\n",
    "           loc = 'upper left', fontsize = 14);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Checking \n",
    "    \n",
    "What is the accuracy (percentage of correct classifications) on the training set?\n",
    "\n",
    "<details><summary><b>Click here for the answer!</b></summary>\n",
    "<p>\n",
    "    \n",
    "```\n",
    "100%\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>\n",
    "\n",
    "How about on the test set (you have to run the test example through the tree, or look at the figure above)? \n",
    "\n",
    "<details><summary><b>Click here for the answer!</b></summary>\n",
    "<p>\n",
    "    \n",
    "```\n",
    "3/5 or 60%\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We want, of course, to be able to answer the questions in code as well.\n",
    "\n",
    "ypred = model.predict(Xtest) #how to generate predicted labels on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(ytest, ypred) #test score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(ytrain, model.predict(Xtrain)) #train score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our final reflection will be an exercise in picking a different train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainSet2 = LearningSet.iloc[5:,:] #we pick the first 5 objects for test, 5:18 for training\n",
    "\n",
    "TestSet2 = LearningSet.iloc[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go through the motion again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain2 = TrainSet2.drop(['P_NAME','P_HABITABLE'],axis=1)\n",
    "\n",
    "Xtest2 = TestSet2.drop(['P_NAME','P_HABITABLE'],axis=1)\n",
    "\n",
    "ytrain2 = TrainSet2.P_HABITABLE\n",
    "\n",
    "ytest2 = TestSet2.P_HABITABLE\n",
    "\n",
    "### And we are ready to fit the model again with our decision tree!\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=3)\n",
    "\n",
    "model.fit(Xtrain2,ytrain2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now visualize the new tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(\n",
    "            model,\n",
    "            out_file =  dot_data,\n",
    "            feature_names = ['Stellar Mass (M*)', 'Orbital Period (d)', 'Distance (AU)'],\n",
    "            class_names = ['Not Habitable','Habitable'],\n",
    "            filled = True,\n",
    "rounded = True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "nodes = graph.get_node_list()\n",
    "\n",
    "for node in nodes:\n",
    "    if node.get_label():\n",
    "        values = [int(ii) for ii in node.get_label().split('value = [')[1].split(']')[0].split(',')]\n",
    "        values = [255 * v / sum(values) for v in values]\n",
    "        \n",
    "        values = [int(255 * v / sum(values)) for v in values]\n",
    "            \n",
    "        if values[0] > values[1]:\n",
    "            alpha = int(values[0] - values[1])\n",
    "            alpha = '{:02x}'.format(alpha) #turn into hexadecimal\n",
    "            color = '#20 B2 AA'+str(alpha)\n",
    "        else:\n",
    "            alpha = int(values[1] - values[0])\n",
    "            alpha = '{:02x}'.format(alpha)\n",
    "            color = '#FF 00 FF'+str(alpha)\n",
    "        node.set_fillcolor(color)\n",
    "\n",
    "graph.set_dpi('300')\n",
    "\n",
    "Image(graph.create_png())\n",
    "\n",
    "#Image(graph.write_png('Graph.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As you can see, this is quite different from the one we had before!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the accuracy (percentage of correct classifications) on the training set?\n",
    "\n",
    "<details><summary><b>Click here for the answer!</b></summary>\n",
    "<p>\n",
    "\n",
    "```\n",
    "100%\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "How about on the test set? Test your code in the cell below.\n",
    "\n",
    "<details><summary><b>Click here for the answer!</b></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "metrics.accuracy_score(ytest2, model.predict(Xtest2))\n",
    "```\n",
    "\n",
    "```\n",
    "Output: 1.0\n",
    "```\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Enter code in this cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's draw some conclusions together..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- Strengths of DT algorithm? Easy, fast, interpretable!\n",
    "\n",
    "- Limitations? You can only split along one feature at a time; requires feature engineering if you want to consider combinations of features.\n",
    "\n",
    "- Possible concerns? This data set is probably too small for conclusions; the fact that test scores fluctuate so much in response to different train/test set splits is an indication of this."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}